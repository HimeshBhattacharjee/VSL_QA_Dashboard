{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6e9bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found path: D:\\WorkingFolder\\OneDrive - vikramsolar.com\\Desktop\\VSL Projects\\QC\\QC_Data\\Auto Peel Test Result\n",
      "Starting data extraction...\n",
      "  Could not find both Excel files in: D:\\WorkingFolder\\OneDrive - vikramsolar.com\\Desktop\\VSL Projects\\QC\\QC_Data\\Auto Peel Test Result\\OCT-2025\\04.10.2025\\SHIFT-A\\STRINGER-5 UNIT-A\n",
      "  Could not find both Excel files in: D:\\WorkingFolder\\OneDrive - vikramsolar.com\\Desktop\\VSL Projects\\QC\\QC_Data\\Auto Peel Test Result\\OCT-2025\\04.10.2025\\SHIFT-A\\STRINGER-5 UNIT-B\n",
      "  Could not find both Excel files in: D:\\WorkingFolder\\OneDrive - vikramsolar.com\\Desktop\\VSL Projects\\QC\\QC_Data\\Auto Peel Test Result\\OCT-2025\\07.10.2025\\SHIFT-C\\STRINGER-3 UNIT-A\n",
      "  Could not find both Excel files in: D:\\WorkingFolder\\OneDrive - vikramsolar.com\\Desktop\\VSL Projects\\QC\\QC_Data\\Auto Peel Test Result\\OCT-2025\\07.10.2025\\SHIFT-C\\STRINGER-3 UNIT-B\n",
      "  Could not find both Excel files in: D:\\WorkingFolder\\OneDrive - vikramsolar.com\\Desktop\\VSL Projects\\QC\\QC_Data\\Auto Peel Test Result\\OCT-2025\\07.10.2025\\SHIFT-C\\STRINGER-4 UNIT-A\n",
      "  Could not find both Excel files in: D:\\WorkingFolder\\OneDrive - vikramsolar.com\\Desktop\\VSL Projects\\QC\\QC_Data\\Auto Peel Test Result\\OCT-2025\\07.10.2025\\SHIFT-C\\STRINGER-4 UNIT-B\n",
      "Successfully extracted 302 records\n",
      "\n",
      "DataFrame shape: (302, 198)\n",
      "\n",
      "First few records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Shift</th>\n",
       "      <th>Stringer</th>\n",
       "      <th>Unit</th>\n",
       "      <th>PO</th>\n",
       "      <th>Cell_Vendor</th>\n",
       "      <th>Front_1_1</th>\n",
       "      <th>Front_1_2</th>\n",
       "      <th>Front_1_3</th>\n",
       "      <th>Front_1_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Back_15_3</th>\n",
       "      <th>Back_15_4</th>\n",
       "      <th>Back_15_5</th>\n",
       "      <th>Back_15_6</th>\n",
       "      <th>Back_16_1</th>\n",
       "      <th>Back_16_2</th>\n",
       "      <th>Back_16_3</th>\n",
       "      <th>Back_16_4</th>\n",
       "      <th>Back_16_5</th>\n",
       "      <th>Back_16_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-03</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>?PO?</td>\n",
       "      <td>?Cell_Vendor?</td>\n",
       "      <td>2.005</td>\n",
       "      <td>1.871</td>\n",
       "      <td>1.701</td>\n",
       "      <td>3.958</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376</td>\n",
       "      <td>2.797</td>\n",
       "      <td>2.279</td>\n",
       "      <td>3.991</td>\n",
       "      <td>2.068</td>\n",
       "      <td>2.693</td>\n",
       "      <td>3.874</td>\n",
       "      <td>3.344</td>\n",
       "      <td>2.467</td>\n",
       "      <td>3.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-03</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>?PO?</td>\n",
       "      <td>?Cell_Vendor?</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.195</td>\n",
       "      <td>0.923</td>\n",
       "      <td>1.117</td>\n",
       "      <td>...</td>\n",
       "      <td>2.885</td>\n",
       "      <td>2.716</td>\n",
       "      <td>3.606</td>\n",
       "      <td>2.078</td>\n",
       "      <td>1.617</td>\n",
       "      <td>2.949</td>\n",
       "      <td>2.894</td>\n",
       "      <td>3.278</td>\n",
       "      <td>3.030</td>\n",
       "      <td>3.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-03</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>?PO?</td>\n",
       "      <td>?Cell_Vendor?</td>\n",
       "      <td>1.141</td>\n",
       "      <td>1.231</td>\n",
       "      <td>1.397</td>\n",
       "      <td>1.899</td>\n",
       "      <td>...</td>\n",
       "      <td>4.095</td>\n",
       "      <td>3.449</td>\n",
       "      <td>2.474</td>\n",
       "      <td>4.770</td>\n",
       "      <td>1.202</td>\n",
       "      <td>2.160</td>\n",
       "      <td>4.051</td>\n",
       "      <td>3.055</td>\n",
       "      <td>1.474</td>\n",
       "      <td>2.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-03</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>?PO?</td>\n",
       "      <td>?Cell_Vendor?</td>\n",
       "      <td>2.905</td>\n",
       "      <td>3.338</td>\n",
       "      <td>3.790</td>\n",
       "      <td>4.103</td>\n",
       "      <td>...</td>\n",
       "      <td>2.248</td>\n",
       "      <td>1.399</td>\n",
       "      <td>1.868</td>\n",
       "      <td>2.264</td>\n",
       "      <td>2.718</td>\n",
       "      <td>1.223</td>\n",
       "      <td>2.235</td>\n",
       "      <td>2.906</td>\n",
       "      <td>2.054</td>\n",
       "      <td>1.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-03</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>?PO?</td>\n",
       "      <td>?Cell_Vendor?</td>\n",
       "      <td>1.686</td>\n",
       "      <td>2.378</td>\n",
       "      <td>2.778</td>\n",
       "      <td>2.698</td>\n",
       "      <td>...</td>\n",
       "      <td>3.651</td>\n",
       "      <td>4.074</td>\n",
       "      <td>3.269</td>\n",
       "      <td>3.201</td>\n",
       "      <td>2.788</td>\n",
       "      <td>3.734</td>\n",
       "      <td>4.031</td>\n",
       "      <td>3.377</td>\n",
       "      <td>3.054</td>\n",
       "      <td>3.163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Shift  Stringer Unit    PO    Cell_Vendor  Front_1_1  Front_1_2  \\\n",
       "0  2025-10-03     A         1    A  ?PO?  ?Cell_Vendor?      2.005      1.871   \n",
       "1  2025-10-03     A         1    B  ?PO?  ?Cell_Vendor?      0.473      1.195   \n",
       "2  2025-10-03     A         2    A  ?PO?  ?Cell_Vendor?      1.141      1.231   \n",
       "3  2025-10-03     A         2    B  ?PO?  ?Cell_Vendor?      2.905      3.338   \n",
       "4  2025-10-03     A         3    A  ?PO?  ?Cell_Vendor?      1.686      2.378   \n",
       "\n",
       "   Front_1_3  Front_1_4  ...  Back_15_3  Back_15_4  Back_15_5  Back_15_6  \\\n",
       "0      1.701      3.958  ...      1.376      2.797      2.279      3.991   \n",
       "1      0.923      1.117  ...      2.885      2.716      3.606      2.078   \n",
       "2      1.397      1.899  ...      4.095      3.449      2.474      4.770   \n",
       "3      3.790      4.103  ...      2.248      1.399      1.868      2.264   \n",
       "4      2.778      2.698  ...      3.651      4.074      3.269      3.201   \n",
       "\n",
       "   Back_16_1  Back_16_2  Back_16_3  Back_16_4  Back_16_5  Back_16_6  \n",
       "0      2.068      2.693      3.874      3.344      2.467      3.164  \n",
       "1      1.617      2.949      2.894      3.278      3.030      3.221  \n",
       "2      1.202      2.160      4.051      3.055      1.474      2.466  \n",
       "3      2.718      1.223      2.235      2.906      2.054      1.915  \n",
       "4      2.788      3.734      4.031      3.377      3.054      3.163  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MongoDB!\n",
      "\n",
      "Working with database: 'peel_test'\n",
      "\n",
      "Processing collection: 'oct_2025'\n",
      "  Created unique index on collection 'oct_2025'\n",
      "  ✓ 302 new records inserted\n",
      "  ✓ 0 existing records updated\n",
      "\n",
      "============================================================\n",
      "SUMMARY:\n",
      "  Total new records inserted: 302\n",
      "  Total records updated: 0\n",
      "  Total errors: 0\n",
      "============================================================\n",
      "\n",
      "Collections in database 'peel_test':\n",
      "  - oct_2025: 302 documents\n",
      "\n",
      "✓ MongoDB connection closed successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from pymongo import MongoClient, ASCENDING\n",
    "from pymongo.errors import ConnectionFailure, DuplicateKeyError, OperationFailure\n",
    "\n",
    "class FuzzyFolderMatcher:\n",
    "    def __init__(self, threshold=80):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def find_best_match(self, target, choices):\n",
    "        if not choices:\n",
    "            return None\n",
    "        best_match, score = process.extractOne(target, choices, scorer=fuzz.token_sort_ratio)\n",
    "        if score >= self.threshold:\n",
    "            return best_match\n",
    "        return None\n",
    "    \n",
    "    def find_files_fuzzy(self, folder_path, target_filename):\n",
    "        if not os.path.exists(folder_path):\n",
    "            return None\n",
    "        files = os.listdir(folder_path)\n",
    "        if target_filename in files:\n",
    "            return os.path.join(folder_path, target_filename)\n",
    "        best_match = self.find_best_match(target_filename, files)\n",
    "        if best_match:\n",
    "            print(f\"  Fuzzy match: '{target_filename}' -> '{best_match}'\")\n",
    "            return os.path.join(folder_path, best_match)\n",
    "        for file in files:\n",
    "            name_without_ext = os.path.splitext(file)[0]\n",
    "            if fuzz.token_sort_ratio(target_filename, name_without_ext) >= self.threshold:\n",
    "                return os.path.join(folder_path, file)\n",
    "        return None\n",
    "\n",
    "def extract_data_from_excel(file_path, sheet_type):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name='Sheet1', header=None)\n",
    "        data_start_row = None\n",
    "        for idx, row in df.iterrows():\n",
    "            if row[0] == 'No.':\n",
    "                data_start_row = idx + 1\n",
    "                break        \n",
    "        if data_start_row is None:\n",
    "            return {}\n",
    "        data_dict = {}\n",
    "        for idx in range(data_start_row, len(df)):\n",
    "            row = df.iloc[idx]\n",
    "            sample_id = str(row[0]).strip()\n",
    "            if pd.isna(sample_id) or 'Gragh' in sample_id or not sample_id:\n",
    "                continue\n",
    "            if '_' in sample_id:\n",
    "                bus_pad_position = int(sample_id.split('_')[-1])\n",
    "                ribbon_data = {}\n",
    "                for ribbon_idx in range(1, 7):\n",
    "                    value = row[ribbon_idx]\n",
    "                    if pd.notna(value):\n",
    "                        ribbon_data[f\"{sheet_type}_{bus_pad_position}_{ribbon_idx}\"] = float(value)\n",
    "                data_dict.update(ribbon_data)\n",
    "        return data_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def parse_folder_structure(root_path):\n",
    "    all_data = []\n",
    "    matcher = FuzzyFolderMatcher(threshold=75)\n",
    "    month_year_patterns = [\n",
    "        re.compile(r'^[A-Z]{3}-\\d{4}$'),\n",
    "    ]    \n",
    "    date_patterns = [\n",
    "        re.compile(r'^\\d{2}\\.\\d{2}\\.\\d{4}$'),\n",
    "        re.compile(r'^\\d{2}-\\d{2}-\\d{4}$'),\n",
    "        re.compile(r'^\\d{2}/\\d{2}/\\d{4}$'),\n",
    "    ]\n",
    "    \n",
    "    shift_patterns = [\n",
    "        re.compile(r'^SHIFT-[ABC]$', re.IGNORECASE),\n",
    "        re.compile(r'^SHIFT\\s+-[ABC]$', re.IGNORECASE),\n",
    "        re.compile(r'^SHIFT-\\s+[ABC]$', re.IGNORECASE),\n",
    "        re.compile(r'^SHIFT\\s+-\\s+[ABC]$', re.IGNORECASE),\n",
    "    ]\n",
    "    \n",
    "    stringer_unit_patterns = [\n",
    "        re.compile(r'^STRINGER-(\\d+)\\s+UNIT-([AB])$', re.IGNORECASE),\n",
    "        re.compile(r'^STRINGER-(\\d+)\\s+UNIT\\s+-([AB])$', re.IGNORECASE),\n",
    "        re.compile(r'^STRINGER-(\\d+)\\s+UNIT-\\s+([AB])$', re.IGNORECASE),\n",
    "        re.compile(r'^STRINGER-(\\d+)\\s+UNIT\\s+-\\s+([AB])$', re.IGNORECASE),\n",
    "        re.compile(r'^STRINGER\\s+-(\\d+)\\s+UNIT-([AB])$', re.IGNORECASE),\n",
    "        re.compile(r'^STRINGER-\\s+(\\d+)\\s+UNIT-([AB])$', re.IGNORECASE),\n",
    "        re.compile(r'^STRINGER\\s+-\\s+(\\d+)\\s+UNIT-([AB])$', re.IGNORECASE),\n",
    "    ]\n",
    "    \n",
    "    def matches_any_pattern(name, patterns):\n",
    "        for pattern in patterns:\n",
    "            if pattern.match(name):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def extract_from_stringer_unit_folder(folder_name, patterns):\n",
    "        for pattern in patterns:\n",
    "            match = pattern.match(folder_name)\n",
    "            if match:\n",
    "                return int(match.group(1)), match.group(2).upper()\n",
    "        return None, None\n",
    "    \n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        current_path = os.path.relpath(root, root_path)\n",
    "        path_parts = current_path.split(os.sep)\n",
    "        if current_path == '.':\n",
    "            continue\n",
    "        if len(path_parts) >= 4:\n",
    "            month_year_folder = path_parts[0]\n",
    "            date_folder = path_parts[1]\n",
    "            shift_folder = path_parts[2]\n",
    "            stringer_unit_folder = path_parts[3]\n",
    "            valid_structure = (\n",
    "                matches_any_pattern(month_year_folder, month_year_patterns) and\n",
    "                matches_any_pattern(date_folder, date_patterns) and\n",
    "                matches_any_pattern(shift_folder, shift_patterns)\n",
    "            )\n",
    "            if valid_structure:\n",
    "                stringer_num, unit = extract_from_stringer_unit_folder(stringer_unit_folder, stringer_unit_patterns)\n",
    "                if stringer_num is not None and unit is not None:\n",
    "                    shift = shift_folder.split('-')[-1].upper() if '-' in shift_folder else shift_folder[-1].upper()\n",
    "                    date_formats = ['%d.%m.%Y', '%d-%m-%Y', '%d/%m/%Y']\n",
    "                    date_str = None\n",
    "                    for date_format in date_formats:\n",
    "                        try:\n",
    "                            date_obj = datetime.strptime(date_folder, date_format)\n",
    "                            date_str = date_obj.strftime('%Y-%m-%d')\n",
    "                            break\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                    if date_str is None:\n",
    "                        print(f\"Could not parse date: {date_folder}\")\n",
    "                        continue\n",
    "                    front_file = matcher.find_files_fuzzy(root, 'FRONT')\n",
    "                    back_file = matcher.find_files_fuzzy(root, 'BACK')\n",
    "                    if not front_file:\n",
    "                        front_file = matcher.find_files_fuzzy(root, 'FRONT.xlsx')\n",
    "                    if not back_file:\n",
    "                        back_file = matcher.find_files_fuzzy(root, 'BACK.xlsx')\n",
    "                    if front_file and back_file:\n",
    "                        front_data = extract_data_from_excel(front_file, 'Front')\n",
    "                        back_data = extract_data_from_excel(back_file, 'Back')\n",
    "                        if front_data and back_data:\n",
    "                            record = {\n",
    "                                'Date': date_str,\n",
    "                                'Shift': shift,\n",
    "                                'Stringer': stringer_num,\n",
    "                                'Unit': unit,\n",
    "                                'PO': '?PO?',\n",
    "                                'Cell_Vendor': '?Cell_Vendor?'\n",
    "                            }\n",
    "                            record.update(front_data)\n",
    "                            record.update(back_data)\n",
    "                            all_data.append(record)\n",
    "                    else:\n",
    "                        print(f\"  Could not find both Excel files in: {root}\")\n",
    "    return all_data\n",
    "\n",
    "def create_structured_dataframe(root_path):\n",
    "    print(\"Starting data extraction...\")\n",
    "    data_records = parse_folder_structure(root_path)    \n",
    "    if not data_records:\n",
    "        print(\"No data found!\")\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(data_records)\n",
    "    base_columns = ['Date', 'Shift', 'Stringer', 'Unit', 'PO', 'Cell_Vendor']\n",
    "    def sort_peel_columns(column_name):\n",
    "        if column_name.startswith('Front_') or column_name.startswith('Back_'):\n",
    "            parts = column_name.split('_')\n",
    "            col_type = parts[0]\n",
    "            bus_pad = int(parts[1])\n",
    "            ribbon = int(parts[2])\n",
    "            return (0 if col_type == 'Front' else 1, bus_pad, ribbon)\n",
    "        else:\n",
    "            return (-1, 0, 0)\n",
    "    peel_columns = [col for col in df.columns if col not in base_columns]\n",
    "    sorted_peel_columns = sorted(peel_columns, key=sort_peel_columns)\n",
    "    final_columns = base_columns + sorted_peel_columns\n",
    "    df = df[final_columns]\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Shift'] = pd.Categorical(df['Shift'], categories=['A', 'B', 'C'], ordered=True)\n",
    "    df['Unit'] = pd.Categorical(df['Unit'], categories=['A', 'B'], ordered=True)\n",
    "    df = df.sort_values(['Date', 'Shift', 'Stringer', 'Unit']).reset_index(drop=True)\n",
    "    df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "    print(f\"Successfully extracted {len(df)} records\")\n",
    "    return df\n",
    "\n",
    "def connect_to_mongodb(connection_string='mongodb://localhost:27017/'):\n",
    "    try:\n",
    "        client = MongoClient(connection_string, serverSelectionTimeoutMS=5000)\n",
    "        client.admin.command('ping')\n",
    "        print(\"Successfully connected to MongoDB!\")\n",
    "        return client\n",
    "    except ConnectionFailure as e:\n",
    "        print(f\"Failed to connect to MongoDB: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to MongoDB: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_collection_name(date_str):\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    month_name = date_obj.strftime('%b').lower()\n",
    "    year = date_obj.strftime('%Y')\n",
    "    return f\"{month_name}_{year}\"\n",
    "\n",
    "def ensure_collection_index(collection):\n",
    "    try:\n",
    "        existing_indexes = collection.index_information()\n",
    "        index_name = 'unique_date_shift_stringer_unit'\n",
    "        index_exists = False\n",
    "        for idx_name, idx_info in existing_indexes.items():\n",
    "            if idx_name == index_name:\n",
    "                index_exists = True\n",
    "                break\n",
    "        if not index_exists:\n",
    "            collection.create_index(\n",
    "                [\n",
    "                    ('Date', ASCENDING),\n",
    "                    ('Shift', ASCENDING),\n",
    "                    ('Stringer', ASCENDING),\n",
    "                    ('Unit', ASCENDING)\n",
    "                ],\n",
    "                unique=True,\n",
    "                name=index_name\n",
    "            )\n",
    "            print(f\"  Created unique index on collection '{collection.name}'\")\n",
    "        else:\n",
    "            print(f\"  Index already exists on collection '{collection.name}'\")\n",
    "    except OperationFailure as e:\n",
    "        print(f\"  Warning: Could not create index on '{collection.name}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Unexpected error while creating index: {e}\")\n",
    "\n",
    "def store_in_mongodb(df, mongo_client, db_name='peel_test'):\n",
    "    if df.empty:\n",
    "        print(\"No data to store in MongoDB\")\n",
    "        return\n",
    "    db = mongo_client[db_name]\n",
    "    print(f\"\\nWorking with database: '{db_name}'\")\n",
    "    df_copy = df.copy()\n",
    "    df_copy['collection_name'] = df_copy['Date'].apply(get_collection_name)\n",
    "    grouped = df_copy.groupby('collection_name')\n",
    "    total_inserted = 0\n",
    "    total_updated = 0\n",
    "    total_errors = 0\n",
    "    for collection_name, group_df in grouped:\n",
    "        print(f\"\\nProcessing collection: '{collection_name}'\")\n",
    "        collection = db[collection_name]\n",
    "        ensure_collection_index(collection)\n",
    "        group_df = group_df.drop('collection_name', axis=1)\n",
    "        records = group_df.to_dict('records')\n",
    "        inserted = 0\n",
    "        updated = 0\n",
    "        errors = 0\n",
    "        for record in records:\n",
    "            try:\n",
    "                filter_query = {\n",
    "                    'Date': record['Date'],\n",
    "                    'Shift': record['Shift'],\n",
    "                    'Stringer': record['Stringer'],\n",
    "                    'Unit': record['Unit']\n",
    "                }\n",
    "                existing_record = collection.find_one(filter_query)\n",
    "                if existing_record:\n",
    "                    needs_update = False\n",
    "                    for key, value in record.items():\n",
    "                        if key in existing_record and existing_record[key] != value:\n",
    "                            needs_update = True\n",
    "                            break\n",
    "                    for key in record.keys():\n",
    "                        if key not in existing_record:\n",
    "                            needs_update = True\n",
    "                            break\n",
    "                    if needs_update:\n",
    "                        collection.update_one(filter_query, {'$set': record})\n",
    "                        updated += 1\n",
    "                else:\n",
    "                    collection.insert_one(record)\n",
    "                    inserted += 1\n",
    "            except DuplicateKeyError:\n",
    "                try:\n",
    "                    collection.update_one(filter_query, {'$set': record})\n",
    "                    updated += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error updating duplicate record: {e}\")\n",
    "                    errors += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing record: {e}\")\n",
    "                errors += 1\n",
    "        total_inserted += inserted\n",
    "        total_updated += updated\n",
    "        total_errors += errors\n",
    "        print(f\"  ✓ {inserted} new records inserted\")\n",
    "        print(f\"  ✓ {updated} existing records updated\")\n",
    "        if errors > 0:\n",
    "            print(f\"  ✗ {errors} errors occurred\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUMMARY:\")\n",
    "    print(f\"  Total new records inserted: {total_inserted}\")\n",
    "    print(f\"  Total records updated: {total_updated}\")\n",
    "    print(f\"  Total errors: {total_errors}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "def list_mongodb_collections(mongo_client, db_name='peel_test'):\n",
    "    try:\n",
    "        db = mongo_client[db_name]\n",
    "        collections = db.list_collection_names()\n",
    "        if collections:\n",
    "            print(f\"\\nCollections in database '{db_name}':\")\n",
    "            for col in collections:\n",
    "                count = db[col].count_documents({})\n",
    "                print(f\"  - {col}: {count} documents\")\n",
    "        else:\n",
    "            print(f\"\\nNo collections found in database '{db_name}'\")\n",
    "        return collections\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing collections: {e}\")\n",
    "        return []\n",
    "\n",
    "def query_mongodb_example(mongo_client, db_name='peel_test', collection_name='jan_2024'):\n",
    "    try:\n",
    "        db = mongo_client[db_name]\n",
    "        if collection_name not in db.list_collection_names():\n",
    "            print(f\"Collection '{collection_name}' does not exist in database '{db_name}'\")\n",
    "            return []\n",
    "        collection = db[collection_name]\n",
    "        all_records = list(collection.find())\n",
    "        print(f\"\\nTotal records in '{collection_name}': {len(all_records)}\")\n",
    "        if all_records:\n",
    "            print(f\"\\nExample record:\")\n",
    "            print(all_records[0])\n",
    "        return all_records\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying MongoDB: {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_path = \"D:\\\\WorkingFolder\\\\OneDrive - vikramsolar.com\\\\Desktop\\\\VSL Projects\\\\QC\\\\QC_Data\\\\Auto Peel Test Result\"\n",
    "    if not os.path.exists(root_path):\n",
    "        print(f\"Path {root_path} does not exist!\")\n",
    "    else:\n",
    "        print(f\"Found path: {root_path}\")\n",
    "    df = create_structured_dataframe(root_path)\n",
    "    if not df.empty:\n",
    "        print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "        print(f\"\\nFirst few records:\")\n",
    "        display(df.head())\n",
    "        mongo_client = connect_to_mongodb('mongodb://localhost:27017/')\n",
    "        if mongo_client:\n",
    "            store_in_mongodb(df, mongo_client, db_name='peel_test')\n",
    "            list_mongodb_collections(mongo_client, db_name='peel_test')\n",
    "            mongo_client.close()\n",
    "            print(\"\\n✓ MongoDB connection closed successfully\")\n",
    "        else:\n",
    "            print(\"\\n✗ Could not connect to MongoDB. Data saved to files only.\")\n",
    "    else:\n",
    "        print(\"No data was extracted. Please check the folder structure and file paths.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
